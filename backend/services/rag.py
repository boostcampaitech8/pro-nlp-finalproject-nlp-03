"""
rag_baseline_upgraded.py
ë ˆì‹œí”¼ RAG ì‹œìŠ¤í…œ - LangChain + CLOVA X + í…ŒìŠ¤íŠ¸
- ClovaXEmbeddings (bge-m3) ì‚¬ìš©
- ChatClovaX (HCX-003) ì‚¬ìš©
- Reranker ì§€ì› (bge-reranker-v2-m3)
- Naive/Advanced RAG í…ŒìŠ¤íŠ¸ + ë¡œê·¸ ì €ì¥ í†µí•©
"""

import json
import os
import hashlib
from typing import List, Dict, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv

# LangChain CLOVA X
try:
    from langchain_naver import ChatClovaX, ClovaXEmbeddings
except ImportError:
    from langchain_community.chat_models import ChatClovaX
    from langchain_community.embeddings import ClovaXEmbeddings

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_community.cross_encoders import HuggingFaceCrossEncoder

# LangChain chains
try:
    from langchain.chains import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
except ImportError:
    from langchain_classic.chains import create_retrieval_chain
    from langchain_classic.chains.combine_documents import create_stuff_documents_chain

# Milvus
try:
    from langchain_milvus import Milvus
except ImportError:
    from langchain_community.vectorstores import Milvus

from pymilvus import connections, utility

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¸íŠ¸
NAIVE_TEST_QUERIES = [
    "ì•„ ë§ë‹¤, ì €ê¸° ìˆì–ì•„. ì˜¤ëŠ˜ ì €ë…ì— ë‚¨í¸ì´ë‘ ëœì¥ì°Œê°œë‚˜ ì¢€ ë“ì—¬ ë¨¹ìœ¼ë ¤ê³  í•˜ëŠ”ë° ë§›ìˆê²Œ ë§Œë“œëŠ” ë°©ë²• ì¢€ ìì„¸íˆ ì•Œë ¤ì¤„ë˜?",
    "ì•„ë‹ˆ ê¸€ì„ ì‹œê³¨ì—ì„œ ê°ìë¥¼ í•œ ë°•ìŠ¤ë‚˜ ë³´ë‚´ì£¼ì…”ì„œ... ê°ìê°€ ì§‘ì— ë„ˆë¬´ ë§ê±°ë“ . ì´ê±° ì²˜ì¹˜ ê³¤ë€ì¸ë° ê°ìì¡°ë¦¼ ë§Œë“œëŠ” ê±° ì¢€ ì°¾ì•„ì¤˜ ë´.",
    "ì–´íœ´, ì–´ì œ ìˆ ì„ ë„ˆë¬´ ë§ì´ ë§ˆì…¨ë‚˜ ë´. ì½©ë‚˜ë¬¼êµ­ ì‹œì›í•˜ê²Œ ë“ì´ëŠ” ë²• ì¢€ ì•Œë ¤ì¤„ë˜? ì† í’€ë¦¬ê²Œ í•´ì¥ìš©ìœ¼ë¡œ ë§ì´ì•¼.",
    "ë‚ ì”¨ê°€ ìŒ€ìŒ€í•´ì§€ë‹ˆê¹Œ ëœ¨ëˆí•œ ê¹€ì¹˜ì°Œê°œê°€ ìƒê°ë‚˜ë„¤. ë¼ì§€ê³ ê¸° íŒíŒ ë„£ê³  ì œëŒ€ë¡œ ê¹Šì€ ë§› ë‚˜ê²Œ ë§Œë“œëŠ” ë¹„ë²• ì¢€ ì•Œë ¤ì¤˜.",
    "ì•„ê¹Œ ë§ˆíŠ¸ ê°”ë”ë‹ˆ ê³ ë“±ì–´ê°€ ì‹±ì‹±í•´ ë³´ì´ë”ë¼ê³ . ê³ ë“±ì–´ì¡°ë¦¼ í•˜ë ¤ëŠ”ë° ë¹„ë¦°ë‚´ ì•ˆ ë‚˜ê³  ë§¤ì½¤í•˜ê²Œ ë§Œë“œëŠ” í™©ê¸ˆ ë ˆì‹œí”¼ ì¢€.",
    "ë¹„ë„ ì˜¤ê³  ê·¸ë˜ì„œ ë¶€ì¹¨ê°œê°€ í™• ë•¡ê¸°ë„¤. ê¹€ì¹˜ì „ ë°”ì‚­ë°”ì‚­í•˜ê²Œ ë§Œë“œëŠ” ê²Œ ì€ê·¼ ì–´ë µë”ë¼ê³ . ëˆ…ëˆ…í•˜ì§€ ì•Šê²Œ ë§Œë“œëŠ” íŒ ì¢€ ì•Œë ¤ì¤˜.",
    "ì˜¤ëŠ˜ ë¹„ë¹”ë°¥ í•´ ë¨¹ì„ ê±´ë°, ê·¸ ë¹„ë¹”ì¥ ì–‘ë… ìˆì§€? ì‹ë‹¹ì—ì„œ íŒŒëŠ” ê²ƒì²˜ëŸ¼ ìƒˆì½¤ë‹¬ì½¤í•˜ê²Œ ë§Œë“œëŠ” ë¹„ìœ¨ ì¢€ ê°€ë¥´ì³ì¤„ë˜?",
]

ADVANCED_TEST_QUERIES = [
    "ìš°ë¦¬ ì• ë“¤ ì˜¤ëŠ˜ ì¼ì° ì˜¤ëŠ”ë°, ê°„ì‹ìœ¼ë¡œ ë–¡ë³¶ì´ ì¢€ í•´ì£¼ë ¤ê³ . ê·¼ë° ì• ë“¤ì´ë¼ ë„ˆë¬´ ë§¤ìš°ë©´ ëª» ë¨¹ìœ¼ë‹ˆê¹Œ ì•ˆ ë§µê²Œ ë§Œë“œëŠ” ë²• ìˆì„ê¹Œ?",
    "ì˜¤ëŠ˜ ì €ë… ë©”ë‰´ëŠ” ì œìœ¡ë³¶ìŒìœ¼ë¡œ ì •í–ˆëŠ”ë°, ë‚´ê°€ ê³ ê¸° ë¹„ë¦°ë‚´ì— ì¢€ ë¯¼ê°í•´ì„œ... ê³ ê¸° ì¡ë‚´ í•˜ë‚˜ë„ ì•ˆ ë‚˜ê²Œ í•˜ëŠ” ë²• ìœ„ì£¼ë¡œ ì•Œë ¤ì¤„ë˜?",
    "ë‚˜ ì§€ê¸ˆ ë°”ë¡œ ë¯¸ì—­êµ­ ë“ì—¬ì•¼ ë˜ëŠ”ë° ëƒ‰ì¥ê³  ë³´ë‹ˆê¹Œ ê³ ê¸°ê°€ ì—†ë„¤? ì†Œê³ ê¸° ì—†ì´ë„ ë§›ìˆê²Œ í•˜ëŠ” ë²• ìˆìœ¼ë©´ ë¹¨ë¦¬ ì¢€ ì•Œë ¤ì¤˜.",
    "ìš”ì¦˜ ê³„ì† ë°°ë‹¬ë§Œ ì‹œì¼œ ë¨¹ì—ˆë”ë‹ˆ ì§€ê²¨ì›Œì„œ... ê·¸ëƒ¥ í˜¼ì ëŒ€ì¶© ë¨¹ì„ ê±°ê±°ë“ . ê³„ë€ë§ì´ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ í•˜ëŠ” ë²• ì—†ì„ê¹Œ?",
    "ìŒ... ê°‘ìê¸° ê¾¸ë•í•œ í¬ë¦¼ íŒŒìŠ¤íƒ€ ê°™ì€ ê²Œ ë§‰ ë¨¹ê³  ì‹¶ë„¤. ìš”ë¦¬ ì´ˆë³´ë„ ì§‘ì—ì„œ ì‰½ê²Œ ë”°ë¼ í•  ìˆ˜ ìˆëŠ” ë²• ì¢€ ê°€ë¥´ì³ì¤˜.",
    "ì €ê¸° ê·¸... ì–´ë””ì„œ ë“¤ì—ˆëŠ”ë° ì¹´ë ˆ í•  ë•Œ ì‚¬ê³¼ë¥¼ ë„£ìœ¼ë©´ í’ë¯¸ê°€ í™• ì‚°ë‹¤ë©°? ì‚¬ê³¼ë¥¼ ì–¸ì œ ì–´ë–»ê²Œ ë„£ì–´ì•¼ í•˜ëŠ”ì§€ ì•Œë ¤ì¤„ ìˆ˜ ìˆì–´?",
    "ì¶œì¶œí•œë° ê°„ì‹ìœ¼ë¡œ ìƒŒë“œìœ„ì¹˜ë‚˜ í•œë²ˆ ë§Œë“¤ì–´ ë³¼ê¹Œ ì‹¶ì–´ì„œ. ëƒ‰ì¥ê³ ì— ìˆëŠ” ì¬ë£Œë¡œ ëŒ€ì¶© ë§Œë“¤ ìˆ˜ ìˆëŠ” ë ˆì‹œí”¼ ì¢€ ë³´ì—¬ì¤˜.",
    "ì•„ ë§ë‹¤, ë‚˜ ì§€ê¸ˆ ë‹¤ì´ì–´íŠ¸ ì¤‘ì¸ ê±° ê¹œë¹¡í–ˆë„¤! ë‹­ê°€ìŠ´ì‚´ë¡œ í•  ìˆ˜ ìˆëŠ” ìš”ë¦¬ ì¤‘ì— ì¹¼ë¡œë¦¬ ë‚®ê³  ë§›ìˆëŠ” ê±° ë­ ì—†ì„ê¹Œ?",
    "ì¹œêµ¬ë“¤ì´ ê°‘ìê¸° ì§‘ìœ¼ë¡œ ì˜¨ë‹¤ëŠ”ë° ì–´ë–¡í•˜ì§€? í•œ 20ë¶„ ì•ˆì— í›„ë‹¤ë‹¥ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê·¼ì‚¬í•œ ì†ë‹˜ ì´ˆëŒ€ ìš”ë¦¬ ì¢€ ì¶”ì²œí•´ ì¤„ë˜?",
    "ì €ê¸°, í˜¹ì‹œ ì§‘ì— ì˜¤ë¸ ì—†ì–´ë„ ì—ì–´í”„ë¼ì´ì–´ë¡œ í†µì‚¼ê²¹ êµ¬ì´ í•  ìˆ˜ ìˆì–´? ì˜¨ë„ë‘ ì‹œê°„ ì„¤ì • ê°™ì€ ê±° ì–´ë–»ê²Œ í•˜ëŠ”ì§€ ì•Œë ¤ì¤˜.",
    "ìš”ì¦˜ ì±„ì†Œë¥¼ ë„ˆë¬´ ì•ˆ ë¨¹ëŠ” ê²ƒ ê°™ì•„ì„œ ë§ì´ì•¼. ì‹œê¸ˆì¹˜ë‚˜ë¬¼ ê°™ì€ ê±° ë°‘ë°˜ì°¬ìœ¼ë¡œ ì¢€ í•´ë‘ë ¤ê³  í•˜ëŠ”ë°, ìƒ‰ê¹” ì•ˆ ë³€í•˜ê²Œ ë¬´ì¹˜ëŠ” ë²• ì•Œì•„?",
    "ì£¼ë§ ì•„ì¹¨ì´ë¼ ì¢€ ê·€ì°®ê¸´ í•œë°... ë¸ŒëŸ°ì¹˜ ëŠë‚Œìœ¼ë¡œë‹¤ê°€ í”„ë Œì¹˜í† ìŠ¤íŠ¸ ì¢€ í•´ë¨¹ìœ¼ë ¤ê³ . ì„¤íƒ• ì ê²Œ ì“°ê³  ë‹¬ì½¤í•˜ê²Œ ë§Œë“œëŠ” ë²• ìˆì„ê¹Œ?",
    "ì•„ì´ê³ , ì§‘ì— ê°„ì¥ì´ ë‹¤ ë–¨ì–´ì¡Œë„¤? ê°„ì¥ ëŒ€ì‹  ì†Œê¸ˆì´ë‚˜ ë‹¤ë¥¸ ê±¸ë¡œ ê°„ ë§ì¶°ì„œ ì¡ì±„ ë§Œë“œëŠ” ë²• í˜¹ì‹œ ì•Œ ìˆ˜ ìˆì„ê¹Œ?",
    "ì• ê¸° ì´ìœ ì‹ ì‹œì‘í•˜ë ¤ê³  í•˜ëŠ”ë°, ì´ˆê¸° ì´ìœ ì‹ìœ¼ë¡œ ë‹¨í˜¸ë°• ë¯¸ìŒ ë§Œë“œëŠ” ê±° ì¢€ ì•Œë ¤ì¤˜. ì•Œë ˆë¥´ê¸° ì£¼ì˜ì‚¬í•­ ê°™ì€ ê²ƒë„ ìˆìœ¼ë©´ ì¢‹ê³ .",
    "ì–´ì œ ë¨¹ë‹¤ ë‚¨ì€ ì¹˜í‚¨ì´ ì²˜ì¹˜ ê³¤ë€ì´ë¼... ì´ê±° í™œìš©í•´ì„œ ì¹˜í‚¨ë§ˆìš” ë®ë°¥ ê°™ì€ ê±° ë§Œë“¤ ìˆ˜ ìˆë‚˜? ë‚¨ì€ ìŒì‹ í™œìš©ë²• ì¢€ ì•Œë ¤ì¤˜.",
    "ì™€ì´í”„ ìƒì¼ì´ë¼ ë¯¸ì—­êµ­ì´ë‘ ê°ˆë¹„ì°œ ì¢€ í•´ì£¼ë ¤ê³  í•˜ëŠ”ë°, ì†Œê°ˆë¹„ì°œ ë¶€ë“œëŸ½ê²Œ í•˜ëŠ” ë²•ì´ ì œì¼ ì¤‘ìš”í•´. ì••ë ¥ì†¥ ì—†ëŠ”ë° ê°€ëŠ¥í• ê¹Œ?",
    "ì €ê¸°ìš”, ì œê°€ ìš”ë¦¬ë¥¼ ì•„ì˜ˆ ëª»í•˜ëŠ” ì†Œìœ„ 'ìš”ì•Œëª»'ì´ê±°ë“ ìš”. ë¼ë©´ë§Œí¼ ì‰¬ìš´ ë³¶ìŒë°¥ ë ˆì‹œí”¼ ë”± í•˜ë‚˜ë§Œ ê³¨ë¼ì¤˜ ë´ìš”.",
    "ìš”ì¦˜ ê±´ê°• ìƒê°í•´ì„œ ì €ì—¼ì‹ í•˜ë ¤ê³  ë…¸ë ¥ ì¤‘ì´ê±°ë“ . ëœì¥ì°Œê°œ ë“ì¼ ë•Œ ì§œì§€ ì•Šê²Œ, ê·¸ëŸ¬ë©´ì„œë„ ë§›ì€ ìˆê²Œ í•˜ëŠ” ë°©ë²• ìˆì„ê¹Œ?",
    "ì•„, ìº í•‘ ì™”ëŠ”ë° ì‚¼ê²¹ì‚´ ë§ê³  ì¢€ íŠ¹ë³„í•œ ê±° í•´ ë¨¹ê³  ì‹¶ì–´ì„œ. ìº í•‘ì¥ì—ì„œ ê·¸ë¦¬ë“¤ í•˜ë‚˜ë¡œ ëë‚¼ ìˆ˜ ìˆëŠ” ìš”ë¦¬ ì¢€ ì¶”ì²œí•´ ì¤„ë˜?",
    "ëª…ì ˆì— ì“°ê³  ë‚¨ì€ ë‚˜ë¬¼ë“¤ì´ ëƒ‰ì¥ê³ ì— ê°€ë“í•´. ì´ê±° í•œêº¼ë²ˆì— ë‹¤ ë„£ê³  ë¹„ë¹”ë°¥ ë§ê³  ì¢€ ìƒ‰ë‹¤ë¥´ê²Œ ë¨¹ëŠ” ë²• ì—†ì„ê¹Œ?",
    "ì•„ì¹¨ì— ë°”ë¹  ì£½ê² ëŠ”ë° ë¹ˆì†ìœ¼ë¡œ ê°€ê¸´ ì¢€ ê·¸ë ‡ê³ ... 5ë¶„ ì•ˆì— ë¹¨ë¦¬ ë¨¹ê³  ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” ì´ˆê°„ë‹¨ ì•„ì¹¨ ì‹ì‚¬ ë©”ë‰´ ì¢€ ì•Œë ¤ì¤„ë˜?",
]


class RecipeRAGLangChain:
    """
    LangChain + CLOVA X ê¸°ë°˜ ë ˆì‹œí”¼ RAG ì‹œìŠ¤í…œ

    Features:
    - ClovaXEmbeddings (bge-m3) for vector search
    - ChatClovaX (HCX-003) for answer generation
    - Optional Reranker (bge-reranker-v2-m3)
    - Naive/Advanced RAG testing with logging
    """

    def __init__(
        self,
        milvus_host: str,
        milvus_port: str,
        collection_name: str,
        use_reranker: bool = False,
        reranker_model: str = "BAAI/bge-reranker-v2-m3",
        chat_model: str = "HCX-003",
        embedding_model: str = "bge-m3",
        temperature: float = 0.2,
        max_tokens: int = 2000,
    ):
        self.milvus_host = milvus_host
        self.milvus_port = milvus_port
        self.milvus_uri = f"http://{milvus_host}:{milvus_port}"
        self.collection_name = collection_name
        self.use_reranker = use_reranker

        print("\n" + "="*60)
        print("Recipe RAG System (LangChain + CLOVA X)")
        print("="*60)

        # 1. CLOVA X Embeddings ì´ˆê¸°í™”
        print(f"\n[1/4] CLOVA X Embeddings ì´ˆê¸°í™” ì¤‘ (model: {embedding_model})")
        self.embeddings = ClovaXEmbeddings(model=embedding_model)
        print("[OK] Embeddings ì´ˆê¸°í™” ì™„ë£Œ")

        # 2. CLOVA X Chat ëª¨ë¸ ì´ˆê¸°í™”
        print(f"\n[2/4] CLOVA X Chat ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ (model: {chat_model})")
        self.chat_model = ChatClovaX(
            model=chat_model,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        print("[OK] Chat ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

        # 3. Reranker ì´ˆê¸°í™” (ì˜µì…˜)
        print("[3/4] Reranker ëª¨ë¸ ë¡œë”© ì¤‘ (model: BAAI/bge-reranker-v2-m3)")
        try:
            from langchain_community.document_compressors import CrossEncoderReranker
            from langchain_community.cross_encoders import HuggingFaceCrossEncoder
            
            # Reranker ëª¨ë¸ ë¡œë“œ
            model = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-v2-m3")
            
            # Reranker ìƒì„±
            self.reranker = CrossEncoderReranker(
                model=model,
                top_n=5  # ìƒìœ„ 5ê°œë§Œ ì„ íƒ
            )
            
            print("[OK] Reranker ì´ˆê¸°í™” ì™„ë£Œ")
            
        except ImportError as e:
            print(f"[WARNING] Reranker ë¡œë”© ì‹¤íŒ¨: {e}")
            print("          sentence-transformers ì„¤ì¹˜ í•„ìš”: pip install sentence-transformers")
            print("          Reranker ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            self.reranker = None
        except Exception as e:
            print(f"[WARNING] Reranker ë¡œë”© ì‹¤íŒ¨: {e}")
            print("          Reranker ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            self.reranker = None

        # 4. Milvus Vectorstore ì—°ê²°
        print(f"\n[4/4] Milvus ì—°ê²° ì¤‘ ({self.milvus_uri})")
        self.vectorstore = None
        self._connect_milvus()

        print("\n" + "="*60)
        print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print("="*60 + "\n")

    def _connect_milvus(self):
        """Milvus vectorstore ì—°ê²°"""
        try:
            self.vectorstore = Milvus(
                embedding_function=self.embeddings,
                collection_name=self.collection_name,
                connection_args={"uri": self.milvus_uri},
                drop_old=False,
            )

            # Sanity check
            sanity_docs = self.vectorstore.similarity_search("ì¡°ë¦¬ë²•", k=1)
            if len(sanity_docs) > 0:
                print(f"[OK] Milvus ì—°ê²° ì„±ê³µ (Collection: {self.collection_name})")
                print(f"     Sanity check: {sanity_docs[0].metadata.get('title', 'N/A')[:50]}...")
            else:
                print(f"[WARNING] Milvus ì—°ê²°ë¨, í•˜ì§€ë§Œ ë¬¸ì„œê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[ERROR] Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def load_recipes(self, json_path: str) -> List[Dict]:
        """ë ˆì‹œí”¼ JSON íŒŒì¼ ë¡œë“œ"""
        print(f"\në ˆì‹œí”¼ íŒŒì¼ ë¡œë“œ ì¤‘: {json_path}")
        with open(json_path, 'r', encoding='utf-8') as f:
            recipes = json.load(f)
        print(f"[OK] ë ˆì‹œí”¼ {len(recipes)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return recipes

    def process_recipe(self, recipe: Dict) -> str:
        """ë ˆì‹œí”¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê²€ìƒ‰ ìµœì í™”)"""
        content_parts = [
            f"ì œëª©: {recipe.get('title', '')}",
            f"ì†Œê°œ: {recipe.get('intro', '')}",
            f"ë¶„ëŸ‰: {recipe.get('portion', '')}",
            f"ì¡°ë¦¬ì‹œê°„: {recipe.get('cook_time', '')}",
            f"ë‚œì´ë„: {recipe.get('level', '')}"
        ]

        # ì¬ë£Œ
        ingredients = recipe.get('ingredients', [])
        if ingredients:
            content_parts.append("\nì¬ë£Œ:")
            for ing in ingredients:
                name = ing.get('name', '')
                amount = ing.get('amount', '')
                desc = ing.get('desc', '')
                ing_text = f"- {name}"
                if amount:
                    ing_text += f" {amount}"
                if desc:
                    ing_text += f" ({desc})"
                content_parts.append(ing_text)

        # ì¡°ë¦¬ë²•
        steps = recipe.get('steps', [])
        if steps:
            content_parts.append("\nì¡°ë¦¬ë²•:")
            for i, step in enumerate(steps, 1):
                step_desc = step.get('desc', '')
                if step_desc:
                    content_parts.append(f"{i}. {step_desc}")

        # íƒœê·¸
        tags = recipe.get('tags', [])
        if tags:
            content_parts.append(f"\níƒœê·¸: {', '.join(tags)}")

        return '\n'.join(content_parts)

    def index_recipes(self, recipes: List[Dict], batch_size: int = 100):
        """ë ˆì‹œí”¼ ì¸ë±ì‹± (LangChain + Milvus)"""
        print("\n" + "="*60)
        print("ë ˆì‹œí”¼ ì¸ë±ì‹± ì‹œì‘")
        print("="*60)

        # Document ê°ì²´ ìƒì„±
        print("\n[1/3] Document ê°ì²´ ìƒì„± ì¤‘...")
        documents = []
        for i, recipe in enumerate(recipes, 1):
            if i % 100 == 0:
                print(f"   ì§„í–‰: {i}/{len(recipes)}")

            content = self.process_recipe(recipe)

            metadata = {
                "recipe_id": str(recipe.get('recipe_id', '')),
                "title": recipe.get('title', ''),
                "author": recipe.get('author', ''),
                "source": recipe.get('detail_url', ''),
                "portion": recipe.get('portion', ''),
                "cook_time": recipe.get('cook_time', ''),
                "level": recipe.get('level', ''),
            }

            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)

        print(f"[OK] Document {len(documents)}ê°œ ìƒì„± ì™„ë£Œ")

        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
        print("\n[2/3] ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ë° ì‚­ì œ...")
        connections.connect(host=self.milvus_host, port=self.milvus_port)
        if utility.has_collection(self.collection_name):
            print(f"      ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {self.collection_name}")
            utility.drop_collection(self.collection_name)

        # Milvusì— ì¸ë±ì‹±
        print("\n[3/3] Milvus ì¸ë±ì‹± ì¤‘ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        self.vectorstore = Milvus.from_documents(
            documents,
            self.embeddings,
            collection_name=self.collection_name,
            connection_args={"uri": self.milvus_uri},
        )

        print("\n" + "="*60)
        print(f"ì¸ë±ì‹± ì™„ë£Œ: ì´ {len(recipes)}ê°œ ë ˆì‹œí”¼")
        print("="*60 + "\n")

    def search_recipes(
        self,
        query: str,
        k: int = 5,
        use_rerank: bool = None
    ) -> List[Dict]:
        """ë ˆì‹œí”¼ ê²€ìƒ‰ (with optional reranking)"""
        use_rerank = use_rerank if use_rerank is not None else self.use_reranker

        # ë²¡í„° ê²€ìƒ‰
        if use_rerank and self.reranker:
            # Reranker ì‚¬ìš© ì‹œ ë” ë§ì´ ê²€ìƒ‰ í›„ rerank
            search_k = k * 3
            docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=search_k)

            # Rerank
            items = []
            for doc, vec_score in docs_with_scores:
                text_short = doc.page_content[:1200]
                rerank_score = float(self.reranker.score([query, text_short]))

                items.append({
                    "document": doc,
                    "vector_score": float(vec_score),
                    "rerank_score": rerank_score,
                })

            # Rerank ì ìˆ˜ë¡œ ì •ë ¬ í›„ ìƒìœ„ kê°œ
            items = sorted(items, key=lambda x: x["rerank_score"], reverse=True)[:k]

            # ê²°ê³¼ í¬ë§·íŒ…
            results = []
            for item in items:
                doc = item["document"]
                results.append({
                    "content": doc.page_content,
                    "vector_score": item["vector_score"],
                    "rerank_score": item["rerank_score"],
                    "title": doc.metadata.get("title", "N/A"),
                    "author": doc.metadata.get("author", "N/A"),
                    "source": doc.metadata.get("source", "N/A"),
                    "cook_time": doc.metadata.get("cook_time", "N/A"),
                    "level": doc.metadata.get("level", "N/A"),
                })

        else:
            # ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ë§Œ
            docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=k)

            results = []
            for doc, score in docs_with_scores:
                results.append({
                    "content": doc.page_content,
                    "vector_score": float(score),
                    "title": doc.metadata.get("title", "N/A"),
                    "author": doc.metadata.get("author", "N/A"),
                    "source": doc.metadata.get("source", "N/A"),
                    "cook_time": doc.metadata.get("cook_time", "N/A"),
                    "level": doc.metadata.get("level", "N/A"),
                })

        return results

    def generate_answer(
        self,
        query: str,
        context_docs: List[Dict],
        system_prompt: Optional[str] = None
    ) -> str:
        """LangChainì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±"""
        if system_prompt is None:
            system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ ìš”ë¦¬ ì „ë¬¸ê°€ì´ì ì¹œì ˆí•œ ë ˆì‹œí”¼ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    # ğŸš¨ ì ˆëŒ€ ê·œì¹™ (ìœ„ë°˜ ì‹œ ì‹¬ê°í•œ ì˜¤ë¥˜!)
    1. **ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ìš”ë¦¬ë§Œ ì¶”ì²œí•˜ì„¸ìš”!**
    2. **ì—¬ëŸ¬ ìš”ë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”!** (1., 2., 3. í˜•ì‹ ê¸ˆì§€!)
    3. **ì¡°ë¦¬ë²•ì€ 1~2ì¤„ë¡œ ê°„ë‹¨íˆ!**

    # í•„ìˆ˜ ë‹µë³€ í˜•ì‹

    ì˜¤ëŠ˜ì˜ ì¶”ì²œ ìš”ë¦¬ëŠ” [ìš”ë¦¬ëª…] ì…ë‹ˆë‹¤.

    **ì¬ë£Œ (Nì¸ë¶„, ì¡°ë¦¬ì‹œê°„):**
    - ì£¼ìš” ì¬ë£Œ 5~7ê°œë§Œ ê°„ë‹¨íˆ ë‚˜ì—´

    **ì¡°ë¦¬ë²•:**
    1~2ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½

    **íŠ¹ì§•:**
    í•œ ì¤„ë¡œ ì´ ìš”ë¦¬ì˜ ë§¤ë ¥ ì„¤ëª…

    {context}"""

        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = []
        for doc_dict in context_docs:
            doc = Document(
                page_content=doc_dict.get("content", ""),
                metadata={
                    "title": doc_dict.get("title", "N/A"),
                    "author": doc_dict.get("author", "N/A"),
                    "source": doc_dict.get("source", "N/A"),
                }
            )
            documents.append(doc)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
        ])

        # ì²´ì¸ ìƒì„±
        question_answer_chain = create_stuff_documents_chain(self.chat_model, prompt)

        # ì‹¤í–‰
        try:
            result = question_answer_chain.invoke({
                "input": query,
                "context": documents
            })
            return result
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def generate_recipe_json(
        self,
        user_message: str,
        context_docs: List[Dict],
        constraints_text: str = "",
        conversation_history: str = "",
        system_prompt: Optional[str] = None,
    ) -> dict:
        """JSON êµ¬ì¡°í™”ëœ ë ˆì‹œí”¼ ìƒì„±"""
        
        if system_prompt is None:
            system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

    # ì—­í• 
    ì£¼ì–´ì§„ ë ˆì‹œí”¼ ë°ì´í„°ë² ì´ìŠ¤ì™€ **ëŒ€í™” íˆìŠ¤í† ë¦¬**ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ìš”ë¦¬ ë ˆì‹œí”¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ **ìƒì„¸í•˜ê²Œ** ìƒì„±í•´ì£¼ì„¸ìš”.

    # ì‚¬ìš©ì ì œì•½ì‚¬í•­
    {constraints_text}

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ë§¤ìš° ì¤‘ìš”!)
    {conversation_history}

    **ì¤‘ìš”**: 
    - ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ì‚¬ìš©ìì˜ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì„ ë°˜ì˜í•˜ì„¸ìš”
    - ì˜ˆ: "ë§¤ì½¤í•˜ê²Œ" â†’ ê³ ì¶§ê°€ë£¨ ì–‘ ì¦ê°€
    - ì˜ˆ: "ê°„ë‹¨í•˜ê²Œ" â†’ ë‹¨ê³„ ìˆ˜ ìµœì†Œí™”
    - ì˜ˆ: "ë¹¨ë¦¬" â†’ ì¡°ë¦¬ ì‹œê°„ ë‹¨ì¶•
    - ì•Œë ˆë¥´ê¸°ì™€ ë¹„ì„ í˜¸ ì¬ë£ŒëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

    # ì¶œë ¥ í˜•ì‹
    ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ ë¶™ì´ì§€ ë§ˆì„¸ìš”:
    {{{{
    "title": "ìš”ë¦¬ ì´ë¦„",
    "intro": "í•œ ì¤„ ì†Œê°œ",
    "cook_time": "ì˜ˆ: 10~15ë¶„",
    "level": "ì˜ˆ: ì´ˆê¸‰",
    "servings": "ì˜ˆ: 2ì¸ë¶„",
    "ingredients": [
        {{{{"name": "ì¬ë£Œëª…", "amount": "ì–‘", "note": "ì„ íƒì‚¬í•­"}}}}
    ],
    "steps": [
        {{{{"no": 1, "desc": "êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì„¤ëª… (ë¶ˆ ì„¸ê¸°, ì‹œê°„, ìˆœì„œ í¬í•¨)"}}}},
        {{{{"no": 2, "desc": "..."}}}}
    ],
    "tips": ["ì‹¤ìš©ì ì¸ íŒ1", "ì‹¤íŒ¨ ë°©ì§€ íŒ2", "ì‘ìš© íŒ3"]
    }}}}

    # ì¡°ë¦¬ë²• ì‘ì„± ê·œì¹™
    - ê° ë‹¨ê³„ëŠ” ë§¤ìš° êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„± (ì˜ˆ: "ì¤‘ë¶ˆì—ì„œ 5ë¶„ê°„", "í™©ê¸ˆìƒ‰ì´ ë  ë•Œê¹Œì§€")
    - ì´ˆë³´ìë„ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê²Œ ì„¤ëª…
    - ì¤‘ìš”í•œ íƒ€ì´ë°ì´ë‚˜ ì£¼ì˜ì‚¬í•­ ëª…ì‹œ
    - ìµœì†Œ 5ë‹¨ê³„ ì´ìƒ ì‘ì„±

    {{context}}"""

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¨¼ì € í¬ë§·íŒ… (constraints_text, conversation_history ì±„ìš°ê¸°)
        formatted_system_prompt = system_prompt.format(
            constraints_text=constraints_text if constraints_text else "ì—†ìŒ",
            conversation_history=conversation_history if conversation_history else "ì—†ìŒ",
            context="{context}"  # ì´ê±´ LangChainì´ ì±„ìš¸ ê±°ë¼ ë‚¨ê²¨ë‘ 
        )

        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = []
        for doc_dict in context_docs:
            doc = Document(
                page_content=doc_dict.get("content", ""),
                metadata={
                    "title": doc_dict.get("title", "N/A"),
                    "author": doc_dict.get("author", "N/A"),
                    "source": doc_dict.get("source", "N/A"),
                }
            )
            documents.append(doc)

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", formatted_system_prompt),
            ("human", "{input}"),
        ])

        # ì²´ì¸ ìƒì„±
        question_answer_chain = create_stuff_documents_chain(self.chat_model, prompt)

        # ì‹¤í–‰
        try:
            result = question_answer_chain.invoke({
                "input": user_message,
                "context": documents,
            })

            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            response_text = result if isinstance(result, str) else str(result)

        except Exception as e:
            print(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return self._get_default_recipe()

        # JSON íŒŒì‹±
        try:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            clean_result = response_text.strip()
            if clean_result.startswith("```json"):
                clean_result = clean_result[7:]
            if clean_result.startswith("```"):
                clean_result = clean_result[3:]
            if clean_result.endswith("```"):
                clean_result = clean_result[:-3]

            parsed_json = json.loads(clean_result.strip())
            print(f"âœ… ë ˆì‹œí”¼ JSON ìƒì„± ì„±ê³µ: {parsed_json.get('title', 'N/A')}")
            return parsed_json

        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì):\n{response_text[:500]}...")
            return self._get_default_recipe()

    def _get_default_recipe(self) -> dict:
        """ê¸°ë³¸ ë ˆì‹œí”¼ ë°˜í™˜ (ì˜¤ë¥˜ ì‹œ)"""
        return {
            "title": "ë ˆì‹œí”¼ ìƒì„± ì‹¤íŒ¨",
            "intro": "ë ˆì‹œí”¼ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "cook_time": "N/A",
            "level": "N/A",
            "servings": "N/A",
            "ingredients": [],
            "steps": [],
            "tips": []
        }

    def query(
        self,
        question: str,
        top_k: int = 5,
        use_rerank: bool = None,
        return_references: bool = True
    ) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (ê²€ìƒ‰ + ìƒì„± í†µí•©)"""
        # 1. ê²€ìƒ‰
        retrieved_docs = self.search_recipes(question, k=top_k, use_rerank=use_rerank)

        # 2. ë‹µë³€ ìƒì„±
        answer = self.generate_answer(question, retrieved_docs)

        result = {
            "question": question,
            "answer": answer,
        }

        if return_references:
            result["references"] = retrieved_docs
            result["num_references"] = len(retrieved_docs)

        return result

    # ========================================
    # í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥ í†µí•©
    # ========================================

    def save_test_log(self, log_data: dict, test_type: str, log_dir: str = "./test_logs"):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSONê³¼ TXTë¡œ ì €ì¥"""
        os.makedirs(log_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # JSON ì €ì¥
        json_filename = f"{log_dir}/{test_type}_{timestamp}.json"
        with open(json_filename, "w", encoding="utf-8") as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)

        # TXT ì €ì¥
        txt_filename = f"{log_dir}/{test_type}_{timestamp}.txt"
        with open(txt_filename, "w", encoding="utf-8") as f:
            f.write("=" * 80 + "\n")
            f.write(f"{test_type.upper().replace('_', ' ')} í…ŒìŠ¤íŠ¸ ê²°ê³¼\n")
            f.write(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")

            for result in log_data.get("results", []):
                f.write(f"\n{'='*80}\n")
                f.write(f"ì§ˆë¬¸: {result.get('question', result.get('query',''))}\n")
                f.write(f"{'='*80}\n\n")
                f.write("ë‹µë³€:\n")
                f.write(f"{result.get('answer','')}\n\n")

                refs = result.get("references", [])
                f.write(f"ì°¸ì¡° ë ˆì‹œí”¼ (ì´ {len(refs)}ê°œ):\n")
                f.write("-" * 80 + "\n")

                for i, ref in enumerate(refs, 1):
                    title = ref.get("title", "N/A")
                    author = ref.get("author", "N/A")
                    cook_time = ref.get("cook_time", "N/A")
                    level = ref.get("level", "N/A")
                    source = ref.get("source", "N/A")

                    f.write(f"\n[Rank {i}] {title}\n")
                    if 'rerank_score' in ref:
                        f.write(f"  Rerank Score: {ref['rerank_score']:.4f}\n")
                    if 'vector_score' in ref:
                        f.write(f"  Vector Score: {ref['vector_score']:.4f}\n")
                    f.write(f"  ì‘ì„±ì: {author}\n")
                    f.write(f"  ë‚œì´ë„: {level} | ì¡°ë¦¬ì‹œê°„: {cook_time}\n")
                    f.write(f"  URL: {source}\n")
                    f.write("-" * 80 + "\n")

        print(f"\n[ë¡œê·¸ ì €ì¥ ì™„ë£Œ]")
        print(f"  JSON: {json_filename}")
        print(f"  TXT:  {txt_filename}")
        return json_filename, txt_filename

    def test_naive_rag(self, queries: List[str] = None, log_dir: str = "./test_logs"):
        """Naive RAG í…ŒìŠ¤íŠ¸ (LangChain RAG Chain ì‚¬ìš©)"""
        if queries is None:
            queries = NAIVE_TEST_QUERIES

        print("\n" + "="*80)
        print("Naive RAG í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"ì´ {len(queries)}ê°œ ì§ˆë¬¸")
        print("="*80)

        log_results = []

        for i, query in enumerate(queries, 1):
            print(f"\n[{i}/{len(queries)}] {query[:50]}...")

            try:
                result = self.query(query, top_k=5, use_rerank=False)
                log_results.append(result)

                # ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°
                answer_preview = result['answer'][:150].replace('\n', ' ')
                print(f"ë‹µë³€: {answer_preview}...")

            except Exception as e:
                print(f"[ERROR] {e}")
                log_results.append({
                    "question": query,
                    "answer": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "references": [],
                    "num_references": 0
                })

        # ë¡œê·¸ ì €ì¥
        log_data = {
            "test_type": "Naive RAG",
            "timestamp": datetime.now().isoformat(),
            "num_queries": len(queries),
            "results": log_results,
        }
        self.save_test_log(log_data, "naive_rag", log_dir)

        print("\n" + "="*80)
        print("Naive RAG í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)

        return log_data

    def test_advanced_rag(self, queries: List[str] = None, log_dir: str = "./test_logs"):
        """Advanced RAG í…ŒìŠ¤íŠ¸ (Reranker ì‚¬ìš©)"""
        if queries is None:
            queries = ADVANCED_TEST_QUERIES

        if not self.use_reranker or not self.reranker:
            print("\n[WARNING] Rerankerê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("          use_reranker=Trueë¡œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
            return None

        print("\n" + "="*80)
        print("Advanced RAG í…ŒìŠ¤íŠ¸ ì‹œì‘ (Reranker ì‚¬ìš©)")
        print(f"ì´ {len(queries)}ê°œ ì§ˆë¬¸")
        print("="*80)

        log_results = []

        for i, query in enumerate(queries, 1):
            print(f"\n[{i}/{len(queries)}] {query[:50]}...")

            try:
                result = self.query(query, top_k=5, use_rerank=True)
                log_results.append(result)

                # ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°
                answer_preview = result['answer'][:150].replace('\n', ' ')
                print(f"ë‹µë³€: {answer_preview}...")

            except Exception as e:
                print(f"[ERROR] {e}")
                log_results.append({
                    "question": query,
                    "answer": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "references": [],
                    "num_references": 0
                })

        # ë¡œê·¸ ì €ì¥
        log_data = {
            "test_type": "Advanced RAG (Reranker)",
            "timestamp": datetime.now().isoformat(),
            "num_queries": len(queries),
            "results": log_results,
        }
        self.save_test_log(log_data, "advanced_rag", log_dir)

        print("\n" + "="*80)
        print("Advanced RAG í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)

        return log_data


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    MILVUS_HOST = "136.113.251.237"
    MILVUS_PORT = "19530"
    COLLECTION_NAME = "recipe_docs"

    print("="*80)
    print("Recipe RAG System")
    print("="*80)

    # API í‚¤ í™•ì¸
    if not os.getenv("CLOVASTUDIO_API_KEY"):
        print("\n[ERROR] CLOVASTUDIO_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = RecipeRAGLangChain(
        milvus_host=MILVUS_HOST,
        milvus_port=MILVUS_PORT,
        collection_name=COLLECTION_NAME,
        use_reranker=True,  # Reranker ì‚¬ìš©
    )

    # ë©”ë‰´
    print("\në©”ë‰´:")
    print("1. ë‹¨ì¼ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸")
    print("2. Naive RAG í…ŒìŠ¤íŠ¸ (7ê°œ)")
    print("3. Advanced RAG í…ŒìŠ¤íŠ¸ (21ê°œ)")
    print("4. ì „ì²´ í…ŒìŠ¤íŠ¸ (28ê°œ)")

    choice = input("\nì„ íƒ (1-4): ").strip()

    if choice == "1":
        query = input("\nì§ˆë¬¸: ")
        result = rag.query(query, top_k=5, use_rerank=True)
        print(f"\në‹µë³€:\n{result['answer']}")
        print(f"\nì°¸ì¡° ë ˆì‹œí”¼ ({result['num_references']}ê°œ):")
        for i, ref in enumerate(result['references'], 1):
            print(f"  [{i}] {ref['title']}")

    elif choice == "2":
        rag.test_naive_rag()

    elif choice == "3":
        rag.test_advanced_rag()

    elif choice == "4":
        rag.test_naive_rag()
        rag.test_advanced_rag()

    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()