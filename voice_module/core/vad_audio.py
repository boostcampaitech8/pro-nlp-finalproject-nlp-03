# import pyaudio
import wave
import torch
import numpy as np
import time
from collections import deque

from pathlib import Path

class VADAudioRecorder:
    def __init__(self):
        self.CHUNK = 512
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        
        # ê¸°ë³¸ VAD ì„¤ì •: ë°˜ì‘ ì†ë„ë¥¼ ìœ„í•´ 0.5ì´ˆë¡œ ì§§ê²Œ ì¡ìŒ
        # self.SILENCE_THRESHOLD = 0.5 
        self.START_THRESHOLD = 0.6   # ë§ ì‹œì‘ ê°ì§€ (ë” ë†’ê²Œ)
        self.END_THRESHOLD   = 0.45  # ë§ ë/ì¹¨ë¬µ íŒì • (ë” ë‚®ê²Œ)
        self.SILENCE_DURATION = 0.5  
        
        # [New] ì™¸ë¶€ì—ì„œ ì„¤ì • ê°€ëŠ¥í•œ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ (ì´ˆ ë‹¨ìœ„)
        # ì´ ì‹œê°„ì´ ì§€ë‚  ë•Œê¹Œì§€ ë§ì„ ì•ˆ í•˜ë©´ Noneì„ ë°˜í™˜í•¨
        self.max_listen_timeout = None 
        self.last_listen_time = time.time()

        print("VAD ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                           model='silero_vad',
                                           force_reload=False,
                                           trust_repo=True)
        (_, _, _, _, _) = utils 
        print("VAD ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
        
        self.p = pyaudio.PyAudio()

    def listen_and_record(self, stop_event=None, out_dir="."):
        stream = self.p.open(format=self.FORMAT,
                             channels=self.CHANNELS,
                             rate=self.RATE,
                             input=True,
                             frames_per_buffer=self.CHUNK)

        print("\nğŸ¤ Listening... (ë§ì”€í•´ ë³´ì„¸ìš”)")
        
        audio_buffer = []
        is_recording = False
        silence_start_time = None
        self.last_listen_time = time.time() # ëŒ€ê¸° ì‹œì‘ ì‹œê°„ ì´ˆê¸°í™”
        
        pre_roll_buffer = deque(maxlen=20)

        while True:
            try:
                # âœ… Streamlit Stop ë²„íŠ¼ì—ì„œ ë©ˆì¶”ê²Œ í•˜ëŠ” í•µì‹¬
                if stop_event is not None and stop_event.is_set():
                    break
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                
                audio_int16 = np.frombuffer(data, dtype=np.int16)
                audio_float32 = audio_int16.astype(np.float32) / 32768.0
                tensor_audio = torch.from_numpy(audio_float32)
                
                speech_prob = self.model(tensor_audio, self.RATE).item()

                # --- 1. ëŒ€ê¸° ìƒíƒœ (Listening) ---
                if not is_recording:
                    pre_roll_buffer.append(data)
                    
                    # (A) ë§ ì‹œì‘ ê°ì§€
                    if speech_prob > self.START_THRESHOLD:
                        print("\nğŸ”´ ê°ì§€ë¨! ë…¹ìŒ ì‹œì‘...")
                        is_recording = True
                        audio_buffer.extend(pre_roll_buffer)
                        silence_start_time = None
                        self.max_listen_timeout = None # ë§ ì‹œì‘í–ˆìœ¼ë‹ˆ íƒ€ì„ì•„ì›ƒ í•´ì œ

                    # (B) íƒ€ì„ì•„ì›ƒ ì²´í¬ (ë§ ì•ˆ í•˜ê³  ë²„í‹°ëŠ” ê²½ìš°)
                    elif self.max_listen_timeout is not None:
                        elapsed = time.time() - self.last_listen_time
                        if elapsed > self.max_listen_timeout:
                            print(f"\nëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({self.max_listen_timeout}s)... ê°•ì œ ì „ì†¡")
                            yield None # íƒ€ì„ì•„ì›ƒ ì‹ í˜¸(None) ì „ì†¡
                            self.max_listen_timeout = None # ë¦¬ì…‹
                            self.last_listen_time = time.time()

                # --- 2. ë…¹ìŒ ìƒíƒœ (Recording) ---
                else:
                    audio_buffer.append(data)
                    
                    if speech_prob > self.END_THRESHOLD:
                        silence_start_time = None
                    else:
                        if silence_start_time is None:
                            silence_start_time = time.time()
                        
                        # ì¹¨ë¬µì´ 0.5ì´ˆ ì§€ì†ë˜ë©´ ë…¹ìŒ ì¢…ë£Œ
                        elif time.time() - silence_start_time > self.SILENCE_DURATION:
                            print("â¹ï¸ 1ì°¨ ë…¹ìŒ ì¢…ë£Œ (ë¶„ì„ ì‹œì‘)")
                            
                            filename = f"voice_input_{int(time.time())}.wav"
                            # self._save_wav(filename, audio_buffer)
                            self._save_wav(str(filename), audio_buffer)
                            
                            # yield filename # íŒŒì¼ëª… ì „ì†¡
                            yield str(filename)
                            
                            # ì´ˆê¸°í™” ë° ë‹¤ì‹œ ëŒ€ê¸°
                            audio_buffer = []
                            is_recording = False
                            pre_roll_buffer.clear()
                            self.last_listen_time = time.time() # ëŒ€ê¸° íƒ€ì´ë¨¸ ë¦¬ì…‹
                            print("\nğŸ¤ Listening...")

            except KeyboardInterrupt:
                break
        
        stream.stop_stream()
        stream.close()

    def _save_wav(self, filename, frames):
        wf = wave.open(filename, 'wb')
        wf.setnchannels(self.CHANNELS)
        wf.setsampwidth(self.p.get_sample_size(self.FORMAT))
        wf.setframerate(self.RATE)
        wf.writeframes(b''.join(frames))
        wf.close()
    
    def close(self):
        self.p.terminate()